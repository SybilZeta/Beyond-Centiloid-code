{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AD dataset:\n",
      "Patients\n",
      "Total: 633, Train: 506, Val: 63, Test: 64\n",
      "Scans\n",
      "Total: 1557, Train: 1221, Val: 163, Test: 173\n",
      "CN dataset:\n",
      "Patients\n",
      "Total: 266, Train: 212, Val: 27, Test: 27\n",
      "Scans\n",
      "Total: 632, Train: 498, Val: 70, Test: 64\n",
      "Patients\n",
      "Total: 899, Train: 719, Val: 90, Test: 90\n",
      "Scans\n",
      "Total: 2189, Train: 1753, Val: 222, Test: 214\n",
      "OASIS3 AD dataset:\n",
      "Patients: 7\n",
      "Scans: 9\n",
      "OASIS3 CN dataset:\n",
      "Patients: 88\n",
      "Scans: 99\n"
     ]
    }
   ],
   "source": [
    "import pytorch_lightning as pl\n",
    "from fdg_simple_classifier import SimpleDataModule, SimpleModel\n",
    "\n",
    "classifier = SimpleModel.load_from_checkpoint('./data_and_models/fdg_auc_roc=0.86.ckpt')\n",
    "dm = SimpleDataModule()\n",
    "dm.setup()\n",
    "test_loader = dm.test_dataloader()\n",
    "external_test_loader = dm.external_test_dataloader()\n",
    "internal_test_loader = dm.internal_test_dataloader()\n",
    "trainer = pl.Trainer()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a CUDA device ('NVIDIA GeForce RTX 4090 D') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "d:\\programs\\Anaconda\\envs\\neuroimaging\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:420: Consider setting `persistent_workers=True` in 'test_dataloader' to speed up the dataloader worker initialization.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0: 100%|██████████| 27/27 [00:02<00:00, 11.69it/s]\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "      Val/accuracy           0.827102780342102\n",
      "       Val/auc_roc          0.9107847213745117\n",
      "         Val/f1             0.8868501782417297\n",
      "         Val/fn                    26.0\n",
      "         Val/fp                    11.0\n",
      "      Val/precision         0.9294871687889099\n",
      "       Val/recall            0.847953200340271\n",
      "         Val/tn                    32.0\n",
      "         Val/tp                    145.0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\programs\\Anaconda\\envs\\neuroimaging\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\logger_connector\\result.py:213: You called `self.log('Val/tn', ...)` in your `on_test_epoch_end` but the value needs to be floating to be reduced. Converting it to torch.float32. You can silence this warning by converting the value to floating point yourself. If you don't intend to reduce the value (for instance when logging the global step or epoch) then you can use `self.logger.log_metrics({'Val/tn': ...})` instead.\n",
      "d:\\programs\\Anaconda\\envs\\neuroimaging\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\logger_connector\\result.py:213: You called `self.log('Val/fp', ...)` in your `on_test_epoch_end` but the value needs to be floating to be reduced. Converting it to torch.float32. You can silence this warning by converting the value to floating point yourself. If you don't intend to reduce the value (for instance when logging the global step or epoch) then you can use `self.logger.log_metrics({'Val/fp': ...})` instead.\n",
      "d:\\programs\\Anaconda\\envs\\neuroimaging\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\logger_connector\\result.py:213: You called `self.log('Val/fn', ...)` in your `on_test_epoch_end` but the value needs to be floating to be reduced. Converting it to torch.float32. You can silence this warning by converting the value to floating point yourself. If you don't intend to reduce the value (for instance when logging the global step or epoch) then you can use `self.logger.log_metrics({'Val/fn': ...})` instead.\n",
      "d:\\programs\\Anaconda\\envs\\neuroimaging\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\logger_connector\\result.py:213: You called `self.log('Val/tp', ...)` in your `on_test_epoch_end` but the value needs to be floating to be reduced. Converting it to torch.float32. You can silence this warning by converting the value to floating point yourself. If you don't intend to reduce the value (for instance when logging the global step or epoch) then you can use `self.logger.log_metrics({'Val/tp': ...})` instead.\n"
     ]
    }
   ],
   "source": [
    "internal_summary = trainer.test(classifier, dataloaders=test_loader)\n",
    "internal_gt = classifier.val_gt\n",
    "internal_preds = classifier.val_pred_AD_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0: 100%|██████████| 27/27 [00:05<00:00,  4.86it/s]\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "      Val/accuracy          0.8644859790802002\n",
      "       Val/auc_roc          0.9016727805137634\n",
      "         Val/f1             0.9144542813301086\n",
      "         Val/fn                    16.0\n",
      "         Val/fp                    13.0\n",
      "      Val/precision         0.9226190447807312\n",
      "       Val/recall           0.9064327478408813\n",
      "         Val/tn                    30.0\n",
      "         Val/tp                    155.0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    }
   ],
   "source": [
    "internal_with_dccc_summary = trainer.test(classifier, dataloaders=internal_test_loader)\n",
    "internal_with_dccc_gt = classifier.val_gt\n",
    "internal_with_dccc_preds = classifier.val_pred_AD_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "d:\\programs\\Anaconda\\envs\\neuroimaging\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:420: Consider setting `persistent_workers=True` in 'test_dataloader' to speed up the dataloader worker initialization.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0: 100%|██████████| 14/14 [00:02<00:00,  6.33it/s]\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "      Val/accuracy          0.7870370149612427\n",
      "       Val/auc_roc          0.8092031478881836\n",
      "         Val/f1             0.34285715222358704\n",
      "         Val/fn                     3.0\n",
      "         Val/fp                    20.0\n",
      "      Val/precision         0.23076923191547394\n",
      "       Val/recall           0.6666666865348816\n",
      "         Val/tn                    79.0\n",
      "         Val/tp                     6.0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    }
   ],
   "source": [
    "external_summary = trainer.test(classifier, dataloaders=external_test_loader)\n",
    "external_gt = classifier.val_gt\n",
    "external_preds = classifier.val_pred_AD_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "z score = 0.90848;\n",
      "p value = 0.36363;\n",
      "There is NO significant difference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\intel\\AppData\\Local\\Temp\\ipykernel_182904\\3276402626.py:26: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  return .5 if Y==X else int(Y < X)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<__main__.DelongTest at 0x207acb47b80>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import scipy.stats as st\n",
    "from sklearn import metrics\n",
    "\n",
    "class DelongTest():\n",
    "    def __init__(self,preds1,preds2,label,threshold=0.05):\n",
    "        '''\n",
    "        preds1:the output of model1\n",
    "        preds2:the output of model2\n",
    "        label :the actual label\n",
    "        '''\n",
    "        self._preds1=preds1\n",
    "        self._preds2=preds2\n",
    "        self._label=label\n",
    "        self.threshold=threshold\n",
    "        self._show_result()\n",
    "\n",
    "    def _auc(self,X, Y)->float:\n",
    "        return 1/(len(X)*len(Y)) * sum([self._kernel(x, y) for x in X for y in Y])\n",
    "\n",
    "    def _kernel(self,X, Y)->float:\n",
    "        '''\n",
    "        Mann-Whitney statistic\n",
    "        '''\n",
    "        return .5 if Y==X else int(Y < X)\n",
    "\n",
    "    def _structural_components(self,X, Y)->list:\n",
    "        V10 = [1/len(Y) * sum([self._kernel(x, y) for y in Y]) for x in X]\n",
    "        V01 = [1/len(X) * sum([self._kernel(x, y) for x in X]) for y in Y]\n",
    "        return V10, V01\n",
    "\n",
    "    def _get_S_entry(self,V_A, V_B, auc_A, auc_B)->float:\n",
    "        return 1/(len(V_A)-1) * sum([(a-auc_A)*(b-auc_B) for a,b in zip(V_A, V_B)])\n",
    "    \n",
    "    def _z_score(self,var_A, var_B, covar_AB, auc_A, auc_B):\n",
    "        return (auc_A - auc_B)/((var_A + var_B - 2*covar_AB )**(.5)+ 1e-8)\n",
    "\n",
    "    def _group_preds_by_label(self,preds, actual)->list:\n",
    "        X = [p for (p, a) in zip(preds, actual) if a]\n",
    "        Y = [p for (p, a) in zip(preds, actual) if not a]\n",
    "        return X, Y\n",
    "\n",
    "    def _compute_z_p(self):\n",
    "        X_A, Y_A = self._group_preds_by_label(self._preds1, self._label)\n",
    "        X_B, Y_B = self._group_preds_by_label(self._preds2, self._label)\n",
    "\n",
    "        V_A10, V_A01 = self._structural_components(X_A, Y_A)\n",
    "        V_B10, V_B01 = self._structural_components(X_B, Y_B)\n",
    "\n",
    "        auc_A = self._auc(X_A, Y_A)\n",
    "        auc_B = self._auc(X_B, Y_B)\n",
    "\n",
    "        # Compute entries of covariance matrix S (covar_AB = covar_BA)\n",
    "        var_A = (self._get_S_entry(V_A10, V_A10, auc_A, auc_A) * 1/len(V_A10)+ self._get_S_entry(V_A01, V_A01, auc_A, auc_A) * 1/len(V_A01))\n",
    "        var_B = (self._get_S_entry(V_B10, V_B10, auc_B, auc_B) * 1/len(V_B10)+ self._get_S_entry(V_B01, V_B01, auc_B, auc_B) * 1/len(V_B01))\n",
    "        covar_AB = (self._get_S_entry(V_A10, V_B10, auc_A, auc_B) * 1/len(V_A10)+ self._get_S_entry(V_A01, V_B01, auc_A, auc_B) * 1/len(V_A01))\n",
    "\n",
    "        # Two tailed test\n",
    "        z = self._z_score(var_A, var_B, covar_AB, auc_A, auc_B)\n",
    "        p = st.norm.sf(abs(z))*2\n",
    "\n",
    "        return z,p\n",
    "\n",
    "    def _show_result(self):\n",
    "        z,p=self._compute_z_p()\n",
    "        print(f\"z score = {z:.5f};\\np value = {p:.5f};\")\n",
    "        if p < self.threshold :print(\"There is a significant difference\")\n",
    "        else:        print(\"There is NO significant difference\")\n",
    "\n",
    "\n",
    "# Model A (random) vs. \"good\" model B\n",
    "DelongTest(internal_preds,internal_with_dccc_preds,internal_gt)\n",
    "\n",
    "\n",
    "# 计算DeLong检验\n",
    "# auc1, auc2, auc_diff, p_value = delong_roc_test(internal_gt, internal_preds, internal_with_dccc_preds)\n",
    "# print(f\"AUC1: {auc1:.3f}, AUC2: {auc2:.3f}, AUC差异: {auc_diff:.3f}, p值: {p_value:.3f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "neuroimaging",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
